{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhrubo0416/Data-Science-Cohort/blob/main/Project_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CHJF68yAIGq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk import pos_tag\n",
        "import numpy as np\n",
        "import pickle\n",
        "import string\n",
        "import random\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIye4PHrBNij",
        "outputId": "59faea11-ada4-41f7-b7a4-108a8cb0750b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rOo1P3znAasu",
        "outputId": "838de891-985c-4f9c-d36d-8b4901f31ee4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           Questions  \\\n",
              "0  What are the job opportunities in government s...   \n",
              "1  What was lowest package in production engineer...   \n",
              "2  What are the prospects of Production Engineeri...   \n",
              "3  Why everyone try for non core jobs is there no...   \n",
              "4  Is there any internship directly given by our ...   \n",
              "\n",
              "                                             Answers  \n",
              "0  There are many opportunities in government sec...  \n",
              "1  Lowest package stands between 4-5 LPA , it als...  \n",
              "2  Production Engineering is a great choice of su...  \n",
              "3  It is true that in core sectors opportunity is...  \n",
              "4  Yes, many companies visit Campus for On Campus...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-137f446b-e87a-4626-8576-74618de1fcfc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Questions</th>\n",
              "      <th>Answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are the job opportunities in government s...</td>\n",
              "      <td>There are many opportunities in government sec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What was lowest package in production engineer...</td>\n",
              "      <td>Lowest package stands between 4-5 LPA , it als...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What are the prospects of Production Engineeri...</td>\n",
              "      <td>Production Engineering is a great choice of su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why everyone try for non core jobs is there no...</td>\n",
              "      <td>It is true that in core sectors opportunity is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Is there any internship directly given by our ...</td>\n",
              "      <td>Yes, many companies visit Campus for On Campus...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-137f446b-e87a-4626-8576-74618de1fcfc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-137f446b-e87a-4626-8576-74618de1fcfc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-137f446b-e87a-4626-8576-74618de1fcfc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "path = (\"/content/drive/MyDrive/Chatbot project final/\")\n",
        "convdata = pd.read_csv(path+'Data_corpus_temp - Sheet1.csv')\n",
        "\n",
        "#show header of the dataset\n",
        "convdata.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd1SncaqAvPb",
        "outputId": "c4298803-4d64-4347-eb11-557054c1bca0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Questions': 'What are the job opportunities in government sector as a production engineer and the name of the companies ?',\n",
              "  'Answers': 'There are many opportunities in government sectors if you get good rank in GATE ME(Mechanical Engineering) : \\n1. Through GATE ME you can get job in PSU. ike : ONGC, NTPC, GAIL,\\n2. You can be an IES officer through ESE.\\n3 .You can be an ISRO,DRDO scientist (ISRO scientist exam ICRB is similar to GATE ME , DRDO scientist is similar to ESE )\\n4. Your can be an government junior engineer through\\xa0SSC\\xa0JE\\xa0exam'},\n",
              " {'Questions': 'What was lowest package in production engineering department of this year?',\n",
              "  'Answers': 'Lowest package stands between 4-5 LPA , it also varies year to year.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#covert dataframes to json\n",
        "convdata_json = json.loads(convdata.to_json(orient='records'))\n",
        "convdata_json[0:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7Bv6KX3AyN8"
      },
      "outputs": [],
      "source": [
        "#export as data as JSON\n",
        "with open(path+'conversation_json.json', 'w') as outfile:\n",
        "    json.dump(convdata_json, outfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLmtejEWA1_2"
      },
      "outputs": [],
      "source": [
        "#greeting function\n",
        "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"good morning\", \"good day\",\"hey\",\"i need help\", \"greetings\")\n",
        "GREETING_RESPONSES = [\"Good day, How may i of help?\", \"Hello, How can i help?\", \"hello\", \"I am glad! You are talking to me.\"]\n",
        "           \n",
        "def greeting(sentence):\n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1cAfLryA3mY"
      },
      "outputs": [],
      "source": [
        "#Wordnet Lemmatization \n",
        "\n",
        "lemmer = nltk.WordNetLemmatizer()\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sREF6DBRCHaq"
      },
      "outputs": [],
      "source": [
        "# Remove punctuation\n",
        "def RemovePunction(tokens):\n",
        "    return[t for t in tokens if t not in string.punctuation]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf1Au-mdLPdK",
        "outputId": "c549b27f-41fd-4ea3-f343-56dbd0288170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179\n",
            "{'further', 'hadn', 're', 'was', 'too', 'over', 'doesn', 'during', 'whom', 'your', 'll', \"won't\", 'what', 'shan', 'has', \"haven't\", 'which', 'he', 'don', 'd', 'again', 'where', 'can', 'under', 'does', \"don't\", \"aren't\", 'until', 'not', \"isn't\", 'doing', 'being', 'but', 'her', 'while', \"you're\", 'out', 'isn', \"mightn't\", 'very', 'shouldn', 'are', 'a', 'won', 'only', 'having', 'we', \"it's\", 'hers', 'did', 'you', 'no', 'they', 'she', 'these', \"needn't\", 'such', 'm', 'himself', 'same', 's', 'had', 'o', 'as', 'their', 'in', 'other', 'there', 'between', 'some', 'most', 'than', \"wouldn't\", 'before', 'from', 'ain', 'haven', 'own', 'mightn', 'after', \"weren't\", 'if', 'hasn', 'here', \"you'd\", 'against', 'them', 'yours', 'off', 'me', 'by', 'because', 'its', 'and', 'at', \"didn't\", 'am', 'when', 'yourselves', \"should've\", 'be', 'been', 've', \"shouldn't\", 'each', \"couldn't\", 'all', 'above', 'theirs', 'it', 'wouldn', 'few', 'through', 'down', 'couldn', 't', 'were', \"hasn't\", 'below', 'herself', 'my', 'of', \"shan't\", 'now', 'mustn', 'ourselves', \"you've\", 'more', 'on', 'have', \"wasn't\", \"mustn't\", 'ours', 'with', 'i', 'do', 'those', 'needn', 'to', \"doesn't\", 'yourself', 'the', 'both', 'aren', 'any', \"that'll\", 'that', 'should', 'myself', \"she's\", 'up', 'once', \"hadn't\", 'themselves', 'our', 'how', 'this', 'weren', 'why', 'so', 'for', \"you'll\", 'didn', 'itself', 'an', 'wasn', 'or', 'will', 'just', 'into', 'then', 'ma', 'his', 'him', 'about', 'who', 'nor', 'y', 'is'}\n"
          ]
        }
      ],
      "source": [
        "# Create a stopword list from the standard list of stopwords available in nltk\n",
        "stop_words = set(stopwords.words('english'))\n",
        "print(len(stop_words))\n",
        "print(stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8DxWv-j7K0Q"
      },
      "outputs": [],
      "source": [
        "def Talk_To_ProdBot(test_set_sentence):\n",
        "    json_file_path = path+\"conversation_json.json\" \n",
        "    tfidf_vectorizer_pickle_path = path + \"tfidf_vectorizer.pkl\"\n",
        "    tfidf_matrix_pickle_path = path+ \"tfidf_matrix_train.pkl\"\n",
        "    \n",
        "    i = 0\n",
        "    sentences = []\n",
        "    \n",
        "    # ---------------Tokenisation of user input -----------------------------#\n",
        "    \n",
        "    tokens = RemovePunction(nltk.word_tokenize(test_set_sentence))\n",
        "    pos_tokens = [word for word,pos in pos_tag(tokens, tagset='universal')]\n",
        "    \n",
        "    word_tokens = LemTokens(pos_tokens)\n",
        "    \n",
        "    filtered_sentence = []\n",
        "    for w in word_tokens: \n",
        "        if w not in stop_words: \n",
        "            filtered_sentence.append(w)  \n",
        "    \n",
        "    filtered_sentence =\" \".join(filtered_sentence).lower()\n",
        "            \n",
        "    test_set = (filtered_sentence, \"\")\n",
        "    \n",
        "    #For Tracing, comment to remove from print.\n",
        "    print('FILTERED INPUT->'+filtered_sentence)\n",
        "    \n",
        "    \n",
        "    # -----------------------------------------------------------------------#\n",
        "        \n",
        "    try: \n",
        "        # ---------------Use Pre-Train Model------------------#\n",
        "        f = open(tfidf_vectorizer_pickle_path, 'rb')\n",
        "        tfidf_vectorizer = pickle.load(f)\n",
        "        f.close()\n",
        "        \n",
        "        f = open(tfidf_matrix_pickle_path, 'rb')\n",
        "        tfidf_matrix_train = pickle.load(f)\n",
        "        f.close()\n",
        "        # ---------------------------------------------------#\n",
        "    except: \n",
        "        # ---------------To Train------------------#\n",
        "        \n",
        "        \n",
        "        \n",
        "        with open(json_file_path) as sentences_file:\n",
        "            reader = json.load(sentences_file)\n",
        "            \n",
        "            # ---------------Tokenisation of training input -----------------------------#    \n",
        "            \n",
        "            for row in reader:\n",
        "                db_tokens = RemovePunction(nltk.word_tokenize(row['Questions']))\n",
        "                pos_db_tokens = [word for word,pos in pos_tag(db_tokens, tagset='universal')]\n",
        "                db_word_tokens = LemTokens(pos_db_tokens)\n",
        "                \n",
        "                db_filtered_sentence = [] \n",
        "                for dbw in db_word_tokens: \n",
        "                    if dbw not in stop_words: \n",
        "                        db_filtered_sentence.append(dbw)  \n",
        "                \n",
        "                db_filtered_sentence =\" \".join(db_filtered_sentence).lower()\n",
        "                \n",
        "                #Debugging Checkpoint\n",
        "                print('TRAINING INPUT: '+db_filtered_sentence)\n",
        "                \n",
        "                sentences.append(db_filtered_sentence)\n",
        "                i +=1                \n",
        "            # ---------------------------------------------------------------------------#\n",
        "                \n",
        "        tfidf_vectorizer = TfidfVectorizer() \n",
        "        tfidf_matrix_train = tfidf_vectorizer.fit_transform(sentences)\n",
        "        #print(tfidf_matrix_train)\n",
        "    \n",
        "        f = open(tfidf_vectorizer_pickle_path, 'wb')\n",
        "        pickle.dump(tfidf_vectorizer, f) \n",
        "        f.close()\n",
        "    \n",
        "        f = open(tfidf_matrix_pickle_path, 'wb')\n",
        "        pickle.dump(tfidf_matrix_train, f) \n",
        "        f.close()\n",
        "        # ------------------------------------------#\n",
        "        \n",
        "    #use the learnt dimension space to run TF-IDF on the query\n",
        "    tfidf_matrix_test = tfidf_vectorizer.transform(test_set)\n",
        "    #print(tfidf_matrix_test)\n",
        "\n",
        "    #then run cosine similarity between the 2 tf-idfs\n",
        "    cosine = cosine_similarity(tfidf_matrix_test, tfidf_matrix_train)\n",
        "\n",
        "    # print only observation and remove it\n",
        "    #print(cosine.argsort())\n",
        "    \n",
        "    #if not in the topic trained.no similarity \n",
        "    idx= cosine.argsort()[0][-2]\n",
        "    flat =  cosine.flatten()\n",
        "    flat.sort()\n",
        "    req_tfidf = flat[-2]\n",
        "    \n",
        "    if (req_tfidf==0): #Threshold A\n",
        "\n",
        "        cosine = np.delete(cosine, 0)\n",
        "        not_understood = \"Apology, I do not understand. Can you repeat it one more time elaborately?\"\n",
        "        \n",
        "        return not_understood\n",
        "        \n",
        "    else:\n",
        "        \n",
        "        #print(cosine)\n",
        "        cosine = np.delete(cosine, 0)\n",
        "        #print(cosine)\n",
        "\n",
        "        #get the max score\n",
        "        max = cosine.max()\n",
        "        response_index = 0\n",
        "\n",
        "        #if max score is lower than < 0.5 > (we see can ask to rephrase.)\n",
        "        if (max <= 0.5): #Threshold B\n",
        "            \n",
        "            not_understood = \"Apology, I do not understand. Can you rephrase?\"\n",
        "            \n",
        "            return not_understood\n",
        "        else:\n",
        "\n",
        "                # else we would simply return the highest score\n",
        "                response_index = np.where(cosine == max)[0][0] + 2 \n",
        "\n",
        "                j = 0 \n",
        "\n",
        "                with open(json_file_path, \"r\") as sentences_file:\n",
        "                    reader = json.load(sentences_file)\n",
        "                    for row in reader:\n",
        "                        j += 1 \n",
        "                        if j == response_index: \n",
        "                            return row[\"Answers\"]\n",
        "                            break\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install gradio"
      ],
      "metadata": {
        "id": "_r6yKmd4WeIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import gradio as gra \n",
        "#app =  gra.Interface(fn = Talk_To_ProdBot , inputs=\"text\", outputs=\"text\", allow_flagging=\"never\")\n",
        "#app.launch(share=True)"
      ],
      "metadata": {
        "id": "MzEBWxWOWtrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y_UB-YT7QYW",
        "outputId": "08555d17-ace5-428b-c872-245c87bd3a1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......................................................................................\n",
            "ProdBot: I am  ProdBot,I will try my best to answer your query\n",
            "ProdBot: If you want to exit, you can type < bye > .\n",
            "......................................................................................\n",
            "USER  :hi\n",
            "......................................................................................\n",
            "ProdBot: Hello, How can i help?\n",
            "......................................................................................\n",
            "USER  :what is the difference between production and mechanical engineering?\n",
            "......................................................................................\n",
            "FILTERED INPUT->difference production mechanical engineering\n",
            "  (0, 253)\t0.31758702750182943\n",
            "  (0, 203)\t0.5675881472289722\n",
            "  (0, 105)\t0.35394558703328627\n",
            "  (0, 84)\t0.6720897979492004\n",
            "ProdBot: Mechanical Engineers focus more on product development works to design and manufacture new products for customers whereas Production Engineers focuses more on making the manufacture more resourceful, Product Engineers work on the products and process designed by Mechanical Engineers.\n",
            "......................................................................................\n",
            "USER  :bye\n",
            "......................................................................................\n",
            "ProdBot: Bye! Hope that i am of help.\n"
          ]
        }
      ],
      "source": [
        "flag=True\n",
        "print(\"......................................................................................\")\n",
        "print( 'ProdBot'+': '+ 'I am  ProdBot,I will try my best to answer your query')\n",
        "print('ProdBot'+':'+ ' If you want to exit, you can type < bye > .')\n",
        "while(flag==True):\n",
        "    print(\"......................................................................................\")\n",
        "    sentence = input(\"USER  \"+\":\")\n",
        "    print(\"......................................................................................\")\n",
        "    if(sentence.lower()!='bye'):\n",
        "        if(greeting(sentence.lower())!=None):\n",
        "            print('ProdBot'+': '+ greeting(sentence.lower()))\n",
        "        else:\n",
        "            response_primary = Talk_To_ProdBot(sentence)\n",
        "            print('ProdBot'+': '+ response_primary)\n",
        "            \n",
        "    else:\n",
        "        flag=False\n",
        "print( 'ProdBot'+': '+\"Bye! Hope that i am of help.\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FwxHJssB_W-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGKc2Z99vyV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c051d0b4-f17c-41d4-c289-f2b0a666d711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlXHoNIIV-5_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1mQWuagQ2GsL1OFJaqltVS3T_J7kIMjCE",
      "authorship_tag": "ABX9TyOBKCE22ZXIWEGYh/nCp0b4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}